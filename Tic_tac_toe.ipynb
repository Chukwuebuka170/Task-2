{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Create a python program that simulates a simple AI agent that can learn to play tic-tac -toe.\n",
        "\n",
        "The program must Define the game board,\n",
        "Check if a player has won, Check if the game is a tie, Main game loop, Call the main game loop."
      ],
      "metadata": {
        "id": "yy2hbgXwoQ45"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeUBkBoLeTgv",
        "outputId": "1edc0112-8314-4af0-a82e-af27cb6b19d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tic-Tac-Toe with a simple learning agent (Q-Learning).\n",
            "Training agent... (this can take a few seconds depending on episodes)\n",
            "Episode 1400/7000, epsilon=0.1971\n",
            "Episode 2800/7000, epsilon=0.1295\n",
            "Episode 4200/7000, epsilon=0.0851\n",
            "Episode 5600/7000, epsilon=0.0559\n",
            "Episode 7000/7000, epsilon=0.0367\n",
            "Training complete and Q-table saved as q_table.pkl\n",
            "Play a game against the agent? (y/n): \n",
            "Goodbye!\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Functions:\n",
        "- display_board(board)\n",
        "- available_moves(board)\n",
        "- make_move(board, idx, player)\n",
        "- check_winner(board)\n",
        "- is_tie(board)\n",
        "- train_q_agent(...)\n",
        "- play_against_agent(...)\n",
        "\"\"\"\n",
        "\n",
        "import random\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "# ---------- Helpers for board and rules ----------\n",
        "WIN_POSITIONS = [\n",
        "    (0,1,2),(3,4,5),(6,7,8),    # rows\n",
        "    (0,3,6),(1,4,7),(2,5,8),    # cols\n",
        "    (0,4,8),(2,4,6)             # diagonals\n",
        "]\n",
        "\n",
        "def display_board(board):\n",
        "    \"\"\"Pretty-print 3x3 board (board is list of 9 strings).\"\"\"\n",
        "    print()\n",
        "    print(f\" {board[0]} | {board[1]} | {board[2]} \")\n",
        "    print(\"---+---+---\")\n",
        "    print(f\" {board[3]} | {board[4]} | {board[5]} \")\n",
        "    print(\"---+---+---\")\n",
        "    print(f\" {board[6]} | {board[7]} | {board[8]} \")\n",
        "    print()\n",
        "\n",
        "def board_to_state(board):\n",
        "    \"\"\"Convert list board to a string state (immutable key).\"\"\"\n",
        "    return ''.join(board)\n",
        "\n",
        "def available_moves(board):\n",
        "    return [i for i, v in enumerate(board) if v == ' ']\n",
        "\n",
        "def make_move(board, idx, player):\n",
        "    board[idx] = player\n",
        "\n",
        "def check_winner(board):\n",
        "    \"\"\"Return 'X' or 'O' if there is a winner, otherwise None.\"\"\"\n",
        "    for a,b,c in WIN_POSITIONS:\n",
        "        if board[a] == board[b] == board[c] and board[a] != ' ':\n",
        "            return board[a]\n",
        "    return None\n",
        "\n",
        "def is_tie(board):\n",
        "    return ' ' not in board and check_winner(board) is None\n",
        "\n",
        "# ---------- Q-learning agent ----------\n",
        "def init_q_for_state(Q, state):\n",
        "    if state not in Q:\n",
        "        Q[state] = [0.0] * 9  # value for each of 9 actions\n",
        "\n",
        "def choose_action_epsilon_greedy(Q, state, board, epsilon=0.1):\n",
        "    moves = available_moves(board)\n",
        "    init_q_for_state(Q, state)\n",
        "    if random.random() < epsilon:\n",
        "        return random.choice(moves)\n",
        "    # pick best among available moves\n",
        "    values = [(Q[state][m], m) for m in moves]\n",
        "    max_val = max(values)[0]\n",
        "    best_moves = [m for v,m in values if v == max_val]\n",
        "    return random.choice(best_moves)\n",
        "\n",
        "def choose_action_greedy(Q, state, board):\n",
        "    moves = available_moves(board)\n",
        "    init_q_for_state(Q, state)\n",
        "    values = [(Q[state][m], m) for m in moves]\n",
        "    max_val = max(values)[0]\n",
        "    best_moves = [m for v,m in values if v == max_val]\n",
        "    return random.choice(best_moves)\n",
        "\n",
        "def train_q_agent(episodes=5000, alpha=0.3, gamma=0.9, epsilon=0.2, eps_decay=0.9997, verbose=False):\n",
        "    \"\"\"\n",
        "    Train a Q-table by playing the Q-agent vs a random agent.\n",
        "    Returns Q (dict).\n",
        "    \"\"\"\n",
        "    Q = {}\n",
        "    for ep in range(episodes):\n",
        "        board = [' '] * 9\n",
        "        # Randomly choose who starts to avoid bias\n",
        "        q_player = 'X' if random.random() < 0.5 else 'O'\n",
        "        other = 'O' if q_player == 'X' else 'X'\n",
        "        state = board_to_state(board)\n",
        "        q_history = []  # only store Q-agent moves as (state, action)\n",
        "        current = 'X'\n",
        "        while True:\n",
        "            if current == q_player:\n",
        "                action = choose_action_epsilon_greedy(Q, state, board, epsilon)\n",
        "                make_move(board, action, q_player)\n",
        "                q_history.append((state, action))\n",
        "            else:\n",
        "                # random opponent\n",
        "                moves = available_moves(board)\n",
        "                action = random.choice(moves)\n",
        "                make_move(board, action, other)\n",
        "\n",
        "            winner = check_winner(board)\n",
        "            if winner or is_tie(board):\n",
        "                # set reward from Q-agent perspective\n",
        "                if winner == q_player:\n",
        "                    reward = 1.0\n",
        "                elif winner is None:\n",
        "                    reward = 0.5  # tie\n",
        "                else:\n",
        "                    reward = -1.0\n",
        "\n",
        "                # Back-propagate reward through agent's history (simple episodic update)\n",
        "                # We go backwards, decaying the reward by gamma\n",
        "                r = reward\n",
        "                for (s,a) in reversed(q_history):\n",
        "                    init_q_for_state(Q, s)\n",
        "                    Q[s][a] += alpha * (r - Q[s][a])\n",
        "                    r *= gamma\n",
        "                break\n",
        "\n",
        "            # continue to next turn\n",
        "            state = board_to_state(board)\n",
        "            current = other if current == q_player else q_player\n",
        "\n",
        "        # decay epsilon slowly (less exploration over time)\n",
        "        epsilon *= eps_decay\n",
        "        if verbose and (ep+1) % (episodes//5) == 0:\n",
        "            print(f\"Episode {ep+1}/{episodes}, epsilon={epsilon:.4f}\")\n",
        "\n",
        "    return Q\n",
        "\n",
        "# ---------- Play against trained agent ----------\n",
        "def play_against_agent(Q, human_player='X'):\n",
        "    \"\"\"\n",
        "    Let a human play against the trained Q-agent.\n",
        "    human_player: 'X' or 'O'\n",
        "    \"\"\"\n",
        "    agent_player = 'O' if human_player == 'X' else 'X'\n",
        "    board = [' '] * 9\n",
        "    current = 'X'\n",
        "    print(\"Positions are numbered 0..8 like this:\")\n",
        "    print(\" 0 | 1 | 2 \")\n",
        "    print(\"---+---+---\")\n",
        "    print(\" 3 | 4 | 5 \")\n",
        "    print(\"---+---+---\")\n",
        "    print(\" 6 | 7 | 8 \")\n",
        "    print()\n",
        "    while True:\n",
        "        display_board(board)\n",
        "        if current == human_player:\n",
        "            moves = available_moves(board)\n",
        "            move = None\n",
        "            while move not in moves:\n",
        "                try:\n",
        "                    move = int(input(f\"Your turn ({human_player}). Choose move (0-8): \").strip())\n",
        "                except:\n",
        "                    move = None\n",
        "            make_move(board, move, human_player)\n",
        "        else:\n",
        "            s = board_to_state(board)\n",
        "            if s not in Q:\n",
        "                # fallback to random if agent hasn't seen this state\n",
        "                move = random.choice(available_moves(board))\n",
        "            else:\n",
        "                move = choose_action_greedy(Q, s, board)\n",
        "            print(f\"Agent ({agent_player}) chooses {move}\")\n",
        "            make_move(board, move, agent_player)\n",
        "\n",
        "        winner = check_winner(board)\n",
        "        if winner or is_tie(board):\n",
        "            display_board(board)\n",
        "            if winner:\n",
        "                print(f\"Winner: {winner}\")\n",
        "            else:\n",
        "                print(\"It's a tie!\")\n",
        "            break\n",
        "        current = 'O' if current == 'X' else 'X'\n",
        "\n",
        "# ---------- Save/Load Q-table helpers ----------\n",
        "def save_q_table(Q, filename=\"q_table.pkl\"):\n",
        "    with open(filename, \"wb\") as f:\n",
        "        pickle.dump(Q, f)\n",
        "\n",
        "def load_q_table(filename=\"q_table.pkl\"):\n",
        "    if os.path.exists(filename):\n",
        "        with open(filename, \"rb\") as f:\n",
        "            return pickle.load(f)\n",
        "    return None\n",
        "\n",
        "# ---------- Main ----------\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Tic-Tac-Toe with a simple learning agent (Q-Learning).\")\n",
        "    # 1) Train\n",
        "    print(\"Training agent... (this can take a few seconds depending on episodes)\")\n",
        "    Q = train_q_agent(episodes=7000, alpha=0.3, gamma=0.9, epsilon=0.3, verbose=True)\n",
        "    save_q_table(Q, \"q_table.pkl\")\n",
        "    print(\"Training complete and Q-table saved as q_table.pkl\")\n",
        "\n",
        "    # 2) Play against trained agent\n",
        "    while True:\n",
        "        ans = input(\"Play a game against the agent? (y/n): \").strip().lower()\n",
        "        if ans in (\"y\",\"yes\"):\n",
        "            # ask which side\n",
        "            side = input(\"Do you want to be X or O? (X plays first): \").strip().upper()\n",
        "            if side not in (\"X\",\"O\"):\n",
        "                side = \"X\"\n",
        "            play_against_agent(Q, human_player=side)\n",
        "        else:\n",
        "            print(\"Goodbye!\")\n",
        "            break\n"
      ]
    }
  ]
}